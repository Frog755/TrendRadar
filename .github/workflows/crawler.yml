name: Hot News Crawler

# è§¦å‘æ–¹å¼ä¿æŒä¸å˜
on:
  schedule:
    # æ¯å°æ—¶æ•´ç‚¹è¿è¡Œï¼ˆå¯è‡ªè¡Œè°ƒæ•´ï¼‰
    - cron: "0 * * * *"
  workflow_dispatch:

# æ˜ç¡®ç»™äºˆå†™å…¥æƒé™ï¼ˆå¿…é¡»ï¼‰
permissions:
  contents: write          # å…è®¸ checkout å’Œ push
  pull-requests: write     # å…è®¸åˆ›å»º Pull Requestï¼ˆå…³é”®ï¼ï¼‰

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0      # å¿…é¡»ï¼Œç¡®ä¿èƒ½è·å–å®Œæ•´å†å²

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Verify required files
        run: |
          echo "ğŸ” æ£€æŸ¥å¿…éœ€çš„é…ç½®æ–‡ä»¶..."
          if [ ! -f config/config.yaml ]; then
            echo "âŒ é”™è¯¯: config/config.yaml æ–‡ä»¶ä¸å­˜åœ¨"
            echo "è¯·å‚è€ƒé¡¹ç›®æ–‡æ¡£åˆ›å»ºé…ç½®æ–‡ä»¶"
            exit 1
          fi
          if [ ! -f config/frequency_words.txt ]; then
            echo "âŒ é”™è¯¯: config/frequency_words.txt æ–‡ä»¶ä¸å­˜åœ¨"
            echo "è¯·å‚è€ƒé¡¹ç›®æ–‡æ¡£åˆ›å»ºé¢‘ç‡è¯é…ç½®æ–‡ä»¶"
            exit 1
          fi
          echo "âœ… é…ç½®æ–‡ä»¶æ£€æŸ¥é€šè¿‡"

      - name: Run crawler
        env:
          FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
          DINGTALK_WEBHOOK_URL: ${{ secrets.DINGTALK_WEBHOOK_URL }}
          WEWORK_WEBHOOK_URL: ${{ secrets.WEWORK_WEBHOOK_URL }}
          WEWORK_MSG_TYPE: ${{ secrets.WEWORK_MSG_TYPE }}
          EMAIL_FROM: ${{ secrets.EMAIL_FROM }}
          EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
          EMAIL_TO: ${{ secrets.EMAIL_TO }}
          EMAIL_SMTP_SERVER: ${{ secrets.EMAIL_SMTP_SERVER }}
          EMAIL_SMTP_PORT: ${{ secrets.EMAIL_SMTP_PORT }}
          NTFY_TOPIC: ${{ secrets.NTFY_TOPIC }}
          NTFY_SERVER_URL: ${{ secrets.NTFY_SERVER_URL }}
          NTFY_TOKEN: ${{ secrets.NTFY_TOKEN }}
          BARK_URL: ${{ secrets.BARK_URL }}
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          GITHUB_ACTIONS: true
        run: python main.py

      # ==================== ä»¥ä¸‹ä¸ºå…¨æ–°ä¸”æ°¸ä¹…ç¨³å®šçš„æäº¤æ–¹æ¡ˆ ====================

      - name: Create new branch & commit changes
        run: |
          BRANCH="crawler-update-$(date +'%Y%m%d-%H%M%S')-${{ github.run_id }}"
          git checkout -b "$BRANCH"
          git add -A
          
          if git diff --staged --quiet; then
            echo "âœ… æ²¡æœ‰æ–‡ä»¶æ”¹åŠ¨ï¼Œè·³è¿‡æäº¤"
            echo "NO_CHANGES=true" >> $GITHUB_ENV
          else
            git commit -m "ğŸ¤– Auto crawled data update $(date '+%Y-%m-%d %H:%M:%S %Z')"
            git push origin "$BRANCH"
            echo "NO_CHANGES=false" >> $GITHUB_ENV
          fi

      - name: Create Pull Request
        if: env.NO_CHANGES != 'true'   # åªæœ‰çœŸæ­£æœ‰æ”¹åŠ¨æ—¶æ‰åˆ›å»º PR
        uses: peter-evans/create-pull-request@v6
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          branch: crawler-update-${{ github.run_id }}-${{ github.run_attempt }}
          base: master
          title: "ğŸ¤– çƒ­ç‚¹æ–°é—»è‡ªåŠ¨æ›´æ–° $(date '+%Y-%m-%d %H:%M:%S')"
          body: |
            è‡ªåŠ¨åŒ–çˆ¬è™«ä»»åŠ¡å·²å®Œæˆå¹¶ç”Ÿæˆæ–°çš„æ•°æ®æ›´æ–°
            
            - Workflow: #${{ github.run_number }}
            - Run ID: ${{ github.run_id }}
            - Trigger: ${{ github.event_name }}
            - Time: $(date '+%Y-%m-%d %H:%M:%S %Z')
          commit-message: "ğŸ¤– Auto crawled data update $(date '+%Y-%m-%d %H:%M:%S')"
          labels: automated,crawler
          delete-branch: true   # åˆå¹¶åè‡ªåŠ¨åˆ é™¤ä¸´æ—¶åˆ†æ”¯
